{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6saTltu6oITY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load\n",
        "df = pd.read_csv('My_Product_Descriptions.csv')\n",
        "\n",
        "\n",
        "# Rename for convenience\n",
        "df = df.rename(columns={'Category': 'label'})\n",
        "df['text'] = df['Product Name'].str.strip() + \" â€” \" + df['Description'].str.strip()\n",
        "\n",
        "# Encode labels\n",
        "label2id = {label: idx for idx, label in enumerate(df['label'].unique())}\n",
        "id2label = {idx: label for label, idx in label2id.items()}\n",
        "df['label_id'] = df['label'].map(label2id)\n",
        "\n",
        "# Train-validation split\n",
        "train_df, val_df = train_test_split(\n",
        "    df, test_size=0.2, stratify=df['label_id'], random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuzHtXqmsSFA"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import DistilBertTokenizerFast\n",
        "import torch\n",
        "\n",
        "# Use DistilBERT tokenizer\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "class ProductDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
        "        self.encodings = tokenizer(\n",
        "            texts,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=max_length\n",
        "        )\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {\n",
        "            key: torch.tensor(val[idx])\n",
        "            for key, val in self.encodings.items()\n",
        "        }\n",
        "        item['labels'] = torch.tensor(self.labels.iloc[idx])\n",
        "        return item\n",
        "\n",
        "# Create datasets and loaders\n",
        "train_dataset = ProductDataset(\n",
        "    train_df['text'].tolist(),\n",
        "    train_df['label_id'],\n",
        "    tokenizer\n",
        ")\n",
        "val_dataset = ProductDataset(\n",
        "    val_df['text'].tolist(),\n",
        "    val_df['label_id'],\n",
        "    tokenizer\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset,   batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpx-YaqbshlF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import DistilBertForSequenceClassification\n",
        "from torch.optim import AdamW\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Load pretrained DistilBERT for classification\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\n",
        "    'distilbert-base-uncased',\n",
        "    num_labels=len(label2id),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ").to(device)\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "# %%\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "epochs = 10\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # Training\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for batch in tqdm(train_loader, desc=f\"Train Epoch {epoch+1}\"):\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "    avg_train_loss = train_loss / len(train_loader)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(val_loader, desc=f\"Val Epoch {epoch+1}\"):\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            outputs = model(**batch)\n",
        "            val_loss += outputs.loss.item()\n",
        "            preds = outputs.logits.argmax(dim=-1)\n",
        "            correct += (preds == batch['labels']).sum().item()\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    val_acc = correct / len(val_dataset)\n",
        "\n",
        "    print(\n",
        "        f\"\\nEpoch {epoch+1} | \"\n",
        "        f\"Train Loss: {avg_train_loss:.4f} | \"\n",
        "        f\"Val Loss: {avg_val_loss:.4f} | \"\n",
        "        f\"Val Acc: {val_acc:.4f}\"\n",
        "    )\n",
        "\n",
        "# %%\n",
        "# Save fine-tuned model & tokenizer\n",
        "model.save_pretrained('distilbert-product-classifier')\n",
        "tokenizer.save_pretrained('distilbert-product-classifier')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgS5DwP8srud"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\n",
        "    \"text-classification\",\n",
        "    model='distilbert-product-classifier',\n",
        "    tokenizer='distilbert-product-classifier',\n",
        "    return_all_scores=False\n",
        ")\n",
        "\n",
        "# Example\n",
        "print(\n",
        "    classifier(\n",
        "        \"Fruity Coffee - A fruity medium roast coffee with notes of caramel\"\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qcpwaews9DO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
